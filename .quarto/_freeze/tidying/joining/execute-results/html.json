{
  "hash": "6d9c51f072f1fb596e399613dd2794ee",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Joining data\nengine: knitr\nformat: live-html\nwebr:\n  packages:\n    - readr\n    - lubridate\n    - tidyr\n    - dplyr\n    - gradethis\n    - readxl\n    - janitor\n    - stringr\nresources:\n  - images\n  - data\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell edit='false'}\n```{webr}\n#| edit: false\n#| output: false\nwebr::install(\"gradethis\", quiet = TRUE)\nlibrary(gradethis)\noptions(webr.exercise.checker = function(\n  label, user_code, solution_code, check_code, envir_result, evaluate_result,\n  envir_prep, last_value, engine, stage, ...\n) {\n  if (is.null(check_code)) {\n    # No grading code, so just skip grading\n    invisible(NULL)\n  } else if (is.null(label)) {\n    list(\n      correct = FALSE,\n      type = \"warning\",\n      message = \"All exercises must have a label.\"\n    )\n  } else if (is.null(solution_code)) {\n    list(\n      correct = FALSE,\n      type = \"warning\",\n      message = htmltools::tags$div(\n        htmltools::tags$p(\"A problem occurred grading this exercise.\"),\n        htmltools::tags$p(\n          \"No solution code was found. Note that grading exercises using the \",\n          htmltools::tags$code(\"gradethis\"),\n          \"package requires a model solution to be included in the document.\"\n        )\n      )\n    )\n  } else {\n    gradethis::gradethis_exercise_checker(\n      label = label, solution_code = solution_code, user_code = user_code,\n      check_code = check_code, envir_result = envir_result,\n      evaluate_result = evaluate_result, envir_prep = envir_prep,\n      last_value = last_value, stage = stage, engine = engine)\n  }\n})\n```\n:::\n\n::: {.cell}\n```{webr}\n#| include: false\n\n#| \n\n#df <- read_csv(\"https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries.csv\")\ndf <- read_csv(\"data/DisasterDeclarationsSummaries.csv\")\n\ncounty_pop <- read_csv(\"data/county_population.csv\")\n#county_pop <- read_csv(\"https://www.andrewbatran.com/data/county_population.csv\")\n\ndf_new <- df |> \n  mutate(GEOID=str_c(fipsStateCode, fipsCountyCode))\n\njoined_new <- left_join(df_new, county_pop, by=\"GEOID\")\n```\n:::\n\n::: {.cell edit='false' define='ok_reponse'}\n```{webr}\n#| edit: false\n#| output: false\n#| define:\n#|   - ok_reponse\nlibrary(htmltools)\nok_reponse <- function(reponse, n) {\n  if (is.na(reponse)) HTML(\"\")\n  else if (reponse == n) div(HTML(\"Correct ✓\"), style = \"color: green\")\n  else div(HTML(\"Incorrect ✗\"), style = \"color: red\")\n}\n```\n:::\n\n\n\n\n\n## Intro\n\n\nWe've done some basic exploring of the FEMA disaster declaration data. \n\nBut there are only so many different ways to slice the data based on the variables in the original data set.\n\nSo we have to be creative and think of what other variables we can add.\n\nLast time, we added some decades categories using the `case_when()` and `mutate()` functions.\n\nBut let's go even further by adding an additional data set.\n\nLet's bring in county population data from the U.S. Census so we can estimate how many people were affected by different disasters.\n\nFor this exercise, the data's already pre-loaded but these are the commands to bring it in yourself using the excellent package called [**tidycensus**](https://learn.r-journalism.com/en/mapping/static_maps/static-maps/) (you'll need to sub in your own Census [API key](https://api.census.gov/data/key_signup.html)). Usually, you'd have to search for and download this from data.census.gov and do some manual cleaning up before using. But using this package that interfaces with the Census API using the lines of code below gives you the data cleaned up and in a **tidy** format.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# this is the code to bring in the data but it's already preloaded in this tutorial\nlibrary(tidycensus)\ncensus_api_key(\"API_KEY_GOES_HERE\")\n\ncounty_pop <- get_acs(geography=\"county\", variables=\"B01003_001\", year=2022)\n```\n:::\n\n\n\n\nLet's take a moment to talk about the significance of **tidy** data. It's the prefix to a lot of the packages and functions we're using in this class. But it's also a philosophy when approaching the structure of data.\n\nThere's an ideal structure for how to stack your data.\n\nAnd that's with \n\n1. Each **variable** is in its own **column**\n2. Each **case** is in its own **row**\n3. Each **value** is in its own **cell**\n\nLet's take a look at the new `county_pop` data frame we imported from the Census API.\n\n\n::: { .panel-tabset}\n\n## Exercise\n\n\n\n\n::: {.cell exercise='glimpse_county_pop'}\n```{webr}\n#| exercise: glimpse_county_pop\n# use the function on the object you just imported from the Census API\n```\n:::\n\n\n\n\n## Hint\n\n::: { .hint exercise=\"glimpse_county_pop\"}\n\nThe function starts with a *g*\n\n:::\n\n## Solution\n\n::: { .solution exercise=\"glimpse_county_pop\"}\n\n\n\n::: {.cell exercise='glimpse_county_pop' solution='true'}\n```{webr}\n#| exercise: glimpse_county_pop\n#| solution: true\nglimpse(county_pop)\n```\n:::\n\n::: {.cell exercise='glimpse_county_pop' check='true'}\n```{webr}\n#| exercise: glimpse_county_pop\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n\n:::\n\n::::\n\nPay attention to the column names and what kind of data is in each column.\n\nNext, let's take a look at our original FEMA data set.\n\n\n\n\n\n::: {.cell}\n```{webr}\ndf <- read_csv(\"https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries.csv\")\n```\n:::\n\n\n\n\n::: { .panel-tabset}\n\n## Exercise\n\n\n\n\n::: {.cell exercise='glimpse'}\n```{webr}\n#| exercise: glimpse\n______(df)\n```\n:::\n\n\n\n\n## Hint\n\n::: { .hint exercise=\"glimpse\"}\nThe function starts with a *g*\n:::\n\n## Solution\n\n::: { .solution exercise=\"glimpse\"}\n\n\n\n::: {.cell exercise='glimpse' solution='true'}\n```{webr}\n#| exercise: glimpse\n#| solution: true\nglimpse(df)\n```\n:::\n\n::: {.cell exercise='glimpse' check='true'}\n```{webr}\n#| exercise: glimpse\n#| check: true\ngrade_this_code()\n```\n:::\n\n\n\n:::\n::::\n\n\n**In each data set, which columns share the most similarity for locations?**\n\n\n\n```{ojs}\n//| echo: false\nmutable ok_reponse2 = (reponse, n) => { return html`Loading...` };\nviewof reponse2 = Inputs.radio(\n  new Map([\n    [\"GEOID in df and placeCode in county_pop\", 1],\n    [\"designatedArea in df and NAME in county_pop\", 2],\n    [\"variable in county_pop and id in df\", 3],\n    [\"estimate in county_pop and disasterNumber in county_pop\", 4]\n  ])\n);\nok_reponse2(reponse2, 2);\n```\n\n\n\n\n## Joins\n\nA join combines two data sets by adding the columns of one data set alongside the columns of the other, usually some of the rows of the second data set along with some rows of the first data set.\n\nA successful join requires something consistent between two data sets to match on: keys.\n\nThe function that's used most often is `left_join()` because you have one main data set you'd like to supplement with additional columns.\n\nHere's how that looks in action:\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/left-join.gif){width=400px}\n:::\n:::\n\n\n\n\nThe function works like this:\n\n\n**If the two data frames you want to join have the same name:**\n\n```\nleft_join(data_frame1, data_frame2, by=\"shared_column_name\")\n```\n\n**If the two data frames you want to join have *different* names:**\n\n```\nleft_join(data_frame1, data_frame2, by=c(\"df1_column\"=\"df_2_column\"))\n```\n\nNotice that the `c()` argument in the second example is different from how we've used it before as combine. The `=` column matching operator is specific to `_join()` functions. Type `?left_join()` in the R console to see all the other arguments you can use.\n\nNow there are a few other joins that have their uses.\n\n* [right_join()](https://github.com/gadenbuie/tidyexplain/blob/main/images/right-join.gif)\n* [full_join()](https://github.com/gadenbuie/tidyexplain/blob/main/images/full-join.gif)\n* [semi_join()](https://github.com/gadenbuie/tidyexplain/raw/main/images/semi-join.gif)\n* [anti_join()](https://github.com/gadenbuie/tidyexplain/raw/main/images/anti-join.gif)\n\nSo let's try to create a new dataframe object starting with the disaster declarations of `df`.\n\nIf you looked at the two dataframes in the last exercise, you saw that there were similarities in the county names.\n\n\n\n\n::: {.cell}\n```{webr}\nglimpse(df)\nglimpse(county_pop)\n```\n:::\n\n\n\n\nTry the `left_join()` function below using the correct syntax and columns you identified.\n\n::: {.panel-tabset}\n\n## Exercise\n\n\n\n\n::: {.cell exercise='true'}\n```{webr}\n#| exercise: true\njoined <- left_join(df, __________, by=_____________)\n\nglimpse(joined)              \n```\n:::\n\n\n\n\n## Hint\n\n::: {.hint exercise=\"left_join\"}\nLook at the example on how to join data frames with different column names above.\n:::\n\n## Solution\n\n::: { .solution exercise=\"left_join\"}\n\n\n\n::: {.cell exercise='left_join' solution='true'}\n```{webr}\n#| exercise: left_join\n#| solution: true\njoined <- left_join(df, county_pop, by=c(\"designatedArea\"=\"NAME\"))\n                    \nglimpse(joined)              \n```\n:::\n\n::: {.cell exercise='left_join' check='true'}\n```{webr}\n#| exercise: left_join\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n\n:::\n::::\n\nAlright, did this work?\n\nWe started out with 24 columns in `df` and now have 28 in the newly created `joined` data frame.\n\nSo columns were added. But did the data come with it?\n\nWhen you scroll to the bottom of the `glimpse()` output you see a bunch of `NA`s.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/fail.png){width=400px}\n:::\n:::\n\n\n\n\n### So what happened?\n\nlet's take a closer look at the first five data points in the two columns we joined on:\n\n::: { .panel-tabset}\n\n## Exercise\n\n\n\n::: {.cell exercise='closer'}\n```{webr}\n#| exercise: closer\ndf |> \n  select(designatedArea) |> \n  slice(___) |> \n  pull(designatedArea)\n\ncounty_pop |> \n  select(NAME) |> \n  slice(___) |> \n  pull(NAME)\n```\n:::\n\n\n\n\n## Hint\n\n::: { .hint exercise=\"closer\"}\nDon't forget the operator that represents \"through\"\n:::\n\n## Solution\n\n::: { .solution exercise=\"closer\"}\n\n\n\n\n::: {.cell exercise='closer' solution='true'}\n```{webr}\n#| exercise: closer\n#| solution: true\ndf |> \n  select(designatedArea) |> \n  slice(1:5) |> \n  pull(designatedArea)\n\ncounty_pop |> \n  select(NAME) |> \n  slice(1:5) |> \n  pull(NAME)\n```\n:::\n\n::: {.cell exercise='closer' check='true'}\n```{webr}\n#| exercise: closer\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n\n\n:::\n::::\n\nAlright, so even though they both contain county names the syntax is completely different.\n\nThe `df` data frame has parentheses around \"County\" and the `county_pop` data frame has a comma followed by the state names.\n\nThis is why the join ultimately failed. \n\nIt's quite deceptive. You ran the code and didn't get an error.\n\nThis is why it's so important to get into the habit of checking for `NA`s after a join or inspecting the new data frame.\n\nFailed joins have thrown off [many](https://www.thekeycuts.com/dear-analyst-a-spreadsheet-error-that-potentially-led-to-incorrect-economic-and-austerity-policies-after-2008-recession/) data analyses and will continue to do so.\n\n**How to join these data sets**\n\nThe best way to join data is using a uniform identification number.\n\nFor the Census, they have standardized county numbers called GEOIDS. These geographical entities [also exist](https://www.census.gov/programs-surveys/geography/guidance/geo-identifiers.html) for census tracts and states and other Census boundaries.\n\nSo the `county_pop` data frame has a column called `GEOID` -- that's perfect!\n\nIt looks like `df` has a column called `fipsCountyCode` but if you joined on those two columns, you'd still fail.\n\nThat's because `GEOID` in `county_pop` is 5 characters wide and `fipsCountyCode` in `df` is 3 characters wide.\n\nData is rarely ready to join straight out the box. \n\nIt will take some more wrangling to get these data sets to join.\n\nIf you've had some experience with working with Census data then you know a county GEOID has 5 characters.\n\nTherefore we need to transform `fipsCountyCode` in `df` by adding `fipsStateCode` in front of it.\n\nTo do that, we'll use a new function from a new package, [**stringr**](https://stringr.tidyverse.org/).\n\n## stringr intro\n\nThere are many wonderful functions in the [**stringr**](https://stringr.tidyverse.org/) package that you do things like detect patterns, see if strings start with with a pattern, or split or join or substitute strings. \n\nIn this instance, we need to combine strings.\n\nWe'll use the `str_c()` function. *Get it? It's short for String Combine.*\n\nUsing `mutate()` we'll also name the new column the same one in the `county_pop` so it's easier to join.\n\n::: {.panel-tabset}\n\n## Exercise\n\n\n\n::: {.cell exercise='str_c'}\n```{webr}\n#| exercise: str_c\n#library(stringr)\n#if you've loaded tidyverse, you've already loaded stringr\n\ndf_new <- df |> \n  mutate(GEOID=____(fipsStateCode, fipsCountyCode))\n\ndf_new |> \n  select(fipsStateCode, fipsCountyCode, GEOID) |> \n  glimpse()\n```\n:::\n\n\n\n\n## Hint\n\n::: {.hint exercise=\"str_c\"}\nfunction starts with an *s*.\n:::\n\n## Solution\n\n::: {.solution exercise=\"str_c\"}\n\n\n\n::: {.cell exercise='str_c' solution='true'}\n```{webr}\n#| exercise: str_c\n#| solution: true\ndf_new <- df |> \n  mutate(GEOID=str_c(fipsStateCode, fipsCountyCode))\n\ndf_new |> \n  select(fipsStateCode, fipsCountyCode, GEOID) |> \n  glimpse()\n```\n:::\n\n::: {.cell exercise='str_c' check='true'}\n```{webr}\n#| exercise: str_c\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n\n\n:::\n::::\n\nAlright! Now let's join `df_new` and `county_pop` like before.\n\n::: {.panel-tabset}\n\n## Exercise\n\n\n\n\n::: {.cell exercise='left_join2'}\n```{webr}\n#| exercise: left_join2\njoined_new <- _____join(df_new, __________, by=_______)\n\nglimpse(joined_new)              \n```\n:::\n\n\n\n\n## Hint\n\n::: {.hint exercise=\"left_join2\"}\nLook at the example on how to join data frames with different column names above.\n:::\n\n## Solution\n\n::: {.solution exercise=\"left_join2\"}\n\n\n\n::: {.cell exercise='left_join2' solution='true'}\n```{webr}\n#| exercise: left_join2\n#| solution: true\njoined_new <- left_join(df_new, county_pop, by=\"GEOID\")\n                    \nglimpse(joined_new)              \n```\n:::\n\n::: {.cell exercise='left_join2' check='true'}\n```{webr}\n#| exercise: left_join2\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n\n:::\n::::\n\nAha! We did it! \n\nLet's do some quick analysis on it.\n\n## Summarize\n\nNow that we have population data with every declared disaster, let's see which 5 disaster type affected the most people in 2021 (sorted high to low).\n\nFill in the missing code.\n\n::: {.panel-tabset}\n\n## Exercise\n\n\n\n\n::: {.cell exercise='summarize'}\n```{webr}\n#| exercise: summarize\njoined_new |> \n  mutate(year=____(incidentBeginDate)) |> \n  filter(______) |> \n  group_by(______) |> \n  summarize(population=sum(estimate, na.rm=T)) |> \n  arrange(______) |> \n  slice(___)\n```\n:::\n\n\n\n\n## Hint\n\n::: {.hint exercise=\"summarize\"}\nThis is a summation of all the functions you've used so far!\n:::\n\n## Solution\n\n::: {.solution exercise=\"summarize\"}\n\n\n\n::: {.cell exercise='summarize' solution='true'}\n```{webr}\n#| exercise: summarize\n#| solution: true\njoined_new |> \n  mutate(year=year(incidentBeginDate)) |> \n  filter(year==2021) |> \n  group_by(incidentType) |> \n  summarize(population=sum(estimate, na.rm=T)) |> \n  arrange(desc(population)) |> \n  slice(1:5)\n```\n:::\n\n::: {.cell exercise='summarize' check='true'}\n```{webr}\n#| exercise: summarize\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n\n\n:::\n::::\n\n### Types of data\n\n* **Categorical variables** are descriptive labels given to individual records, assigning them to different groups. The simplest categorical data is dichotomous, meaning that there are just two possible groups — in an election, for instance, people either voted, or they did not. More commonly, there are multiple categories. When analyzing traffic accidents, for example, you might consider the day of the week on which each incident occurred, giving seven possible categories.\n* **Continuous data** is richer, consisting of numbers that can have a range of values on a sliding scale. When working with weather data, for instance, continuous variables might include temperature and amount of rainfall.\n\nWe also often need to consider date and time, which can be treated as continuous, like a sequence of years; or categorical, like the days of the week. A common task in data stories is to consider how the values for a variable or variables have changed over time.\n\n### Interviewing data\n\nThe goal is to get used to asking questions of data by performing the following basic operations with the functions you've learned:\n\n* **Sort**: Largest to smallest, oldest to newest, alphabetical etc.\n* **Filter**: Select a defined subset of the data.\n* **Summarize**: Derive one value from a series of other values to produce a summary statistic. Examples include:\n  * **Count**. The number of records.\n  * **Sum**. Add the values of a continuous variable.\n  * **Mean** (aka average). The sum of values for a continuous variable divided by the count.\n  * **Median**. The value in the middle, if the values for a continuous variable are sorted in ascending or descending order of magnitude.\n  * **Max**, **Min**. The largest and smallest value for a continuous value, respectively.\n* Math: Move the summarized data into a new sheet for additional analysis\n\nOften you will **group by** a *categorical* variable first, and then summarize a *continuous* variable for each category.\n\nLet's try to summarize a different way. We added up the population for all incident types in 2021. \n\nBut this time, let's find the average and median population affected by all incident types in the entire data set.\n\nArrange it high to low (on avg_pop) and slice out the top 5 rows.\n\n::: {.panel-tabset}\n\n## Exercise\n\n\n\n\n::: {.cell exercise='summarize_again'}\n```{webr}\n#| exercise: summarize_again\njoined_new |> \n  group_by(___________) |> \n  summarize(declarations=___,\n            avg_pop=____(estimate, na.rm=T),\n            median_pop=______(estimate, na.rm=T)) |> \n  arrange(___________) |> \n  slice(___)\n```\n:::\n\n\n\n\n## Hint\n::: {.hint exercise=\"summarize_again\"}\nthe function to find average is mean()\n:::\n\n## Solution\n\n::: {.solution exercise=\"summarize_again\"}\n\n\n\n::: {.cell exercise='summarize_again' solution='true'}\n```{webr}\n#| exercise: summarize_again\n#| solution: true\njoined_new |> \n  group_by(incidentType) |> \n  summarize(declarations=n(),\n            avg_pop=mean(estimate, na.rm=T),\n            median_pop=median(estimate, na.rm=T)) |> \n  arrange(desc(avg_pop)) |> \n  slice(1:5)\n```\n:::\n\n::: {.cell exercise='summarize_again' check='true'}\n```{webr}\n#| exercise: summarize_again\n#| check: true\ngradethis::grade_this_code()\n```\n:::\n\n\n\n\nPretty interesting, right? \n\nI don't know if this could lead to a story because the top three incident types that affected the highest average amount of people occurred so rarely. \n\n## Newsroom math\n\nNearly every news story that involves data analysis can be derived from one these formulas.\n\n* Difference\n  * x - y\n* Percent\n  * x / (x + y) * 100\n* Percent change\n  * (new - old)/old * 100\n* Per Capita\n  * x / population * some multiplier to raise result to a round number\n\nSo let's say we want to write a story about Kentucky flooding.\n\nOne thing we can ask is what has changed? Have things gotten worse or have things improved?\n\nLet's wrangle the data so we can easily answer that.\n\nWe'll need to only compare the current months of 2022 with the past months (otherwise we'd be comparing 12 months of data in 2021 to 8 in 2022 which would be misleading).\n\n\n\n\n::: {.cell}\n\n```{.webrr .cell-code}\njoined_new |> \n  filter(state==\"KY\") |> \n  filter(incidentType==\"Flood\") |> \n  mutate(year=year(incidentBeginDate)) |> \n  # extracting months\n  mutate(month=month(incidentBeginDate)) |> \n  # only paying attention to months in current year of data set\n  filter(month %in% c(1:8)) |> \n  filter(year==2020 | year==2021 | year==2022) |> \n  group_by(year) |> \n  summarize(declarations=n(),\n            avg_pop=mean(estimate, na.rm=T),\n            median_pop=median(estimate, na.rm=T))\n```\n:::\n\n\n\n\nTo answer the quiz, use this exercise box below.\n\n\n\n\n::: {.cell exercise='true'}\n\n:::\n\n\n\n\n**How many more county Flood declarations were there in Kentucky in 2021 compared to 2022?**\n\n\n\n\n```{ojs}\n//| echo: false\nmutable ok_reponse = (reponse, n) => { return html`Loading...` };\nviewof reponse = Inputs.radio(\n  new Map([\n    [\"3\", 1],\n    [\"30\", 2],\n    [\"-19\", 3],\n    [\"-5\", 4]\n  ])\n);\nok_reponse(reponse, 2);\n```\n\n\n\n\n**What's the percent change between county flood declarations in Kentucky between 2022 and 2021?**\n\n\n\n```{ojs}\n//| echo: false\nmutable ok_reponse = (reponse, n) => { return html`Loading...` };\nviewof reponse = Inputs.radio(\n  new Map([\n    [\"-60\", 1],\n    [\"60\", 2],\n    [\"50\", 3],\n    [\"-100\", 4]\n  ])\n);\nok_reponse(reponse, 2);\n```\n\n\n\n\n\nGreat job so far.\n\nBefore we try out more math we'll need to learn more techniques to transform the data.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}